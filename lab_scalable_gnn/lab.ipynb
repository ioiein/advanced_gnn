{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of lab_scalable_gnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZT4qfpC0Sja"
      },
      "source": [
        "# Lab — Scalable GNN\n",
        "\n",
        "Today we will talk about application of Graph Neural Networks to large graphs, specifically, we will explain in details how GraphSAINT (Graph Sampling based Inductive Learning Method https://arxiv.org/abs/1907.04931) works.\n",
        "\n",
        "Classic GCN samplings works in layer-wise nature. For example, GraphSAGE samples the neighborhood of each node to aggregate into the anchor node embedding. The general idea of GraphSAINT is to sample subgraphs from the large graph and train the GCN on it. However, such sampling induces bias due to more probable sampling of high degree nodes. To eliminate it, authors propose several normalization and variance-reduction techniques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHex3aef0PL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda924fc-d765-48d8-d5e5-cfd07aa0b808"
      },
      "source": [
        "! pip install ogb -q\n",
        "! pip install dgl-cu111 -f https://data.dgl.ai/wheels/repo.html -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▏                           | 10 kB 21.6 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 30 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 40 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 61 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 78 kB 3.1 MB/s \n",
            "\u001b[?25h  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 164.7 MB 2.9 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIy_54Ea23KK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1307a2-0c60-404d-a4a0-6939d778775b"
      },
      "source": [
        "import dgl\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from abc import ABC, abstractmethod\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "from dgl.sampling import random_walk, pack_traces\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using backend: pytorch\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV5ovDYLFFXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba3c98c-a249-43a6-f3fb-736a2482fd90"
      },
      "source": [
        "from ogb.nodeproppred import DglNodePropPredDataset, Evaluator\n",
        "\n",
        "d_name = \"ogbn-arxiv\"\n",
        "\n",
        "dataset = DglNodePropPredDataset(name=d_name)\n",
        "\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
        "graph, label = dataset[0]\n",
        "\n",
        "graph.ndata[\"label\"] = label.view(-1)\n",
        "graph.ndata[\"is_train\"] = torch.zeros(graph.num_nodes())\n",
        "graph.ndata[\"is_train\"][train_idx] = 1\n",
        "graph.ndata[\"is_train\"] = graph.ndata[\"is_train\"].type(torch.BoolTensor)\n",
        "\n",
        "graph = graph.to(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.08 GB: 100%|██████████| 81/81 [00:03<00:00, 23.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/arxiv.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 7653.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into DGL objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 17.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMHgNlwg4266"
      },
      "source": [
        "$$A H W$$\n",
        "$$(n\\times n)(n \\times d_\\text{in})(d_\\text{in} \\times d_\\text{out}) = (n \\times d_\\text{out})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJBRNRanbPnv"
      },
      "source": [
        "### Subgraph sampling\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/netspractice/advanced_gnn/main/lab_scalable_gnn/graph_sampling.png' width=700>\n",
        "\n",
        "In this task we will define the abstract SamplerBase class and specific realizations of it for different motifs sampling (Node, Edge and Random Walks).\n",
        "\n",
        "The `SamplerBase` inherit the `torch.utils.data.Dataset`. `SamplerBase` takes two input parameters:\n",
        "\n",
        "1. Graph `g` is our graph to be sampled\n",
        "2. `num_nodes` is an expected number of nodes for each subgraph\n",
        "\n",
        "The torch Dataset requires at least two functions to be defined: `__len__` and `__getitem__`.\n",
        "\n",
        "First function should return the total number of samples in the dataset. In the given setting we want to cover the all nodes by subgraphs, so the length of dataset will be equal to the ceil of number of nodes in the graph divided by the number of nodes per subgraph.\n",
        "\n",
        "The second one should return the sample subgraph. To unify it between different sampling techniques (Nodes, Edges and Random Walks), we will call abstract method `__sample__` that returns list of nodes for subgraph. After, we will take the subgraph from the given nodes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCFrttNgcUKJ"
      },
      "source": [
        "class SamplerBase(Dataset, ABC):\n",
        "  def __init__(self, g, num_nodes, seed=0):\n",
        "    self.g = g\n",
        "    self.num_nodes = num_nodes\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "  @abstractmethod\n",
        "  def __sample__(self):\n",
        "    raise NotImplemented\n",
        "  \n",
        "  def __len__(self):\n",
        "    return math.ceil(self.g.num_nodes() / self.num_nodes)\n",
        "\n",
        "  @abstractmethod\n",
        "  def __getitem__(self, idx):\n",
        "    raise NotImplemented"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lHj5oyC-BWC"
      },
      "source": [
        "After defining the base for samplers we can define the specific realizations.\n",
        "\n",
        "The `NodeSampler` just samples with replacement nodes from the graphs according to its input degree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58m8EgFS-LgH"
      },
      "source": [
        "class NodeSampler(SamplerBase):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    self.prob = None\n",
        "    super(NodeSampler, self).__init__(*args, **kwargs)\n",
        "\n",
        "  def __sample__(self):\n",
        "    if self.prob is None:\n",
        "      self.prob = self.g.in_degrees().float().clamp(min=1).to(device)\n",
        "    return torch.multinomial(self.prob, num_samples=self.num_nodes, replacement=True).unique()\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    subgraph_nodes = self.__sample__()\n",
        "    return dgl.node_subgraph(self.g, subgraph_nodes)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35fnW5H0E_sC"
      },
      "source": [
        "node_sampler = NodeSampler(graph, 100)\n",
        "\n",
        "subg = node_sampler.__getitem__(0)\n",
        "assert subg.num_nodes() > 90\n",
        "assert subg.num_nodes() < 110"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5afCjnZF6kOi",
        "outputId": "127859d4-be25-427d-cd8d-6229fe8b54d6"
      },
      "source": [
        "subg.num_nodes()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmn1k8v4-0wB"
      },
      "source": [
        "`EdgeSampler` works as follows:\n",
        "\n",
        "1. Samples edges with _unnormalized_ probability \n",
        "$$p_{u,v} = \\frac{1}{\\text{deg}(u)} + \\frac{1}{\\text{deg}(v)}$$\n",
        "2. Returns unique list of nodes defined by the edges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzlw1_ms-LcO"
      },
      "source": [
        "from time import time\n",
        "\n",
        "class EdgeSampler(SamplerBase):\n",
        "  def __init__(self, num_edges, **kwargs):\n",
        "    self.prob = None\n",
        "    self.num_edges = num_edges\n",
        "    super(EdgeSampler, self).__init__(num_nodes=2 * num_edges, **kwargs)\n",
        "\n",
        "  def __sample__(self):\n",
        "    src, dst = self.g.edges()\n",
        "    if self.prob is None:\n",
        "      src_degrees = self.g.in_degrees(src).float().clamp(min=1)\n",
        "      dst_degrees = self.g.in_degrees(dst).float().clamp(min=1)\n",
        "\n",
        "      self.prob = (1. / src_degrees + 1. / dst_degrees).to(device)\n",
        "      self.prob /= self.prob.sum()\n",
        "    return torch.multinomial(self.prob, self.num_edges, replacement=False)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    subgraph_edges = self.__sample__()\n",
        "    return dgl.edge_subgraph(self.g, subgraph_edges)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZr1s2PmHeQZ"
      },
      "source": [
        "edge_sampler = EdgeSampler(num_edges=256, g=graph)\n",
        "\n",
        "subg = edge_sampler.__getitem__(0)\n",
        "assert subg.num_edges() == 256"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prpvCDBU-6vs"
      },
      "source": [
        "`RandomWalkSampler` works as follows:\n",
        "\n",
        "1. Selects the random root nodes from graph\n",
        "2. Uses `random_walk` method from dgl to sample random walks\n",
        "3. Packs random walk traces with `pack_traces` from dgl\n",
        "4. Returns the received node list from `3`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkfpyznr-LaS"
      },
      "source": [
        "class RandomWalkSampler(SamplerBase):\n",
        "  def __init__(self, num_roots, length, **kwargs):\n",
        "    self.num_roots, self.length = num_roots, length\n",
        "    super(RandomWalkSampler, self).__init__(num_nodes=num_roots * length, **kwargs)\n",
        "  \n",
        "  def __sample__(self):\n",
        "    sampled_roots = torch.randint(0, self.g.num_nodes(), (self.num_roots,))\n",
        "    traces, types = random_walk(self.g, nodes=sampled_roots, length=self.length)\n",
        "    sampled_nodes, _, _, _ = pack_traces(traces, types)\n",
        "    return  sampled_nodes.unique()\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    subgraph_nodes = self.__sample__()\n",
        "    return dgl.node_subgraph(self.g, subgraph_nodes)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhJkg8zK-LXP"
      },
      "source": [
        "rw_sampler = RandomWalkSampler(num_roots=20, length=10, g=graph)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhrNpXoD72aq",
        "outputId": "5a6c1ff9-18a3-462e-c51d-5239a6c5d83f"
      },
      "source": [
        "rw_sampler[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=94, num_edges=150,\n",
              "      ndata_schemes={'year': Scheme(shape=(1,), dtype=torch.int64), 'feat': Scheme(shape=(128,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'is_train': Scheme(shape=(), dtype=torch.bool), '_ID': Scheme(shape=(), dtype=torch.int64)}\n",
              "      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2ATrNdbG0uH"
      },
      "source": [
        "### Precompute normalizations\n",
        "\n",
        "Subgraph sampling induce the bias towards nodes with high degrees due to larger probability to be sampled. So, authors of GraphSAINT propose to use the normalizations. To decrease train time, they fix normalization before starting training by precomputing it on the several samples.\n",
        "\n",
        "To do so, we need to sample several batches of subgraphs and calculate edge, loss and aggregation norms.\n",
        "\n",
        "To simplify our code, we will use custom collate function that will extract node and edge indices and calculate summed number of nodes in the sampled subgraphs.\n",
        "\n",
        "Method `collate_batch` should iterate over each subgraph in the batch, and calculate three variables:\n",
        "\n",
        "1. Number of nodes over all graphs in the batch (not unique, total)\n",
        "2. List of lists with source node ids (`dgl.NID` param of `graph.ndata`)\n",
        "3. List of lists with source edge ids (`dgl.EID` param of `graph.edata`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOA9rzWBIa5s"
      },
      "source": [
        "def collate_batch(batch):\n",
        "  sum_num_nodes = 0\n",
        "  subgraphs_nids_list = []\n",
        "  subgraphs_eids_list = []\n",
        "  for subg in batch:\n",
        "      sum_num_nodes += subg.num_nodes()\n",
        "      subgraphs_nids_list.append(subg.ndata[dgl.NID])\n",
        "      subgraphs_eids_list.append(subg.edata[dgl.EID])\n",
        "  return sum_num_nodes, subgraphs_nids_list, subgraphs_eids_list"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R_TXL6kQE9Q"
      },
      "source": [
        "batch = [graph.subgraph(range(i * 100, (i + 1) * 100)) for i in range(10)]\n",
        "sum_num_nodes, subgraphs_nids_list, subgraphs_eids_list = collate_batch(batch)\n",
        "\n",
        "assert sum_num_nodes == 1000\n",
        "assert len(subgraphs_nids_list) == 10\n",
        "assert len(subgraphs_eids_list) == 10\n",
        "assert min(subgraphs_nids_list[3]) == 300\n",
        "assert max(subgraphs_nids_list[3]) == 399"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0geRyaMpIfDz"
      },
      "source": [
        "Now, we need to define method to compute _aggregator_ and _loss normalizations_, given the node and edge occurencies. The loss normalization is defined as follows:\n",
        "\n",
        "$$\\lambda_{i} = \\frac{N_\\text{samples}}{N_{i} \\cdot N_\\text{nodes}},$$\n",
        "\n",
        "where $N_\\text{samples}$ is a number of subgraphs in the precomputing stage, $N_{i}$ is a number of occurencies of node $i$ in subgraphs and $N_\\text{nodes}$ is a total number of nodes in the graph. The aggregator normalization is defined as follows:\n",
        "\n",
        "$$\\alpha_{u,v} = \\frac{p_{u,v}}{p_v},$$\n",
        "\n",
        "where $p_{u,v}$ is a probability of edge from node $u$ to node $v$ and $p_v$ is a probability of node $v$. To calculate it, one can use dgl message function `fn.e_div_v`.\n",
        "\n",
        "\n",
        "$\\alpha$ will be used as an edge weight in the `GraphConv` layer further. The $\\lambda$ will be used as a observation weight while cross-entropy calculation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IOMHHr69rGV"
      },
      "source": [
        "e = [u, v]\n",
        "u, v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VveFUEzgIxKu"
      },
      "source": [
        "def compute_norm(g, node_counter, edge_counter, num_subgraphs):\n",
        "  node_counter[node_counter == 0] = 1\n",
        "  edge_counter[edge_counter == 0] = 1\n",
        "\n",
        "  loss_norm = num_subgraphs / node_counter / g.num_nodes()\n",
        "  g.ndata['n_c'] = node_counter\n",
        "  g.edata['e_c'] = edge_counter\n",
        "  g.apply_edges(fn.e_div_v('e_c', 'n_c', 'a_n'))\n",
        "  aggr_norm = g.edata.pop('a_n')\n",
        "\n",
        "  g.ndata.pop('n_c'), g.edata.pop('e_c')\n",
        "\n",
        "  return aggr_norm, loss_norm"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x73RaNJxPLqt"
      },
      "source": [
        "g = dgl.rand_graph(10, 30)\n",
        "aggr, loss = compute_norm(\n",
        "    g, \n",
        "    torch.arange(10).type(torch.FloatTensor), \n",
        "    torch.arange(30).type(torch.FloatTensor), \n",
        "    100\n",
        ")\n",
        "assert round(loss[-1].item(), 2) == 1.11"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP72mnplLvJU"
      },
      "source": [
        "Now we are ready to write function for precomputation stage.\n",
        "\n",
        "It should work as follows:\n",
        "\n",
        "1. Initialize DataLoader with input sampler (do not forget to pass the `collate_fn=collate_batch` parameter)\n",
        "2. Iterate until data left or until we receive `num_samples` for each node (break iteration if `num sampled nodes > num_samples * sampler.g.num_nodes`)\n",
        "3. On each iteration calculate\n",
        "  1. total number of sampled nodes \n",
        "  2. total number of subgraphs (`num_subgraphs`)\n",
        "  3. counters for each node (`node_counter`) and edge occurencies (`edge_counter`)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVmV0mwB2wd0"
      },
      "source": [
        "def precompute_norm(sampler, num_samples, batch_size, num_workers):\n",
        "  loader = DataLoader(\n",
        "      sampler, \n",
        "      batch_size=batch_size, \n",
        "      shuffle=True, \n",
        "      num_workers=num_workers, \n",
        "      collate_fn=collate_batch, \n",
        "      drop_last=False)\n",
        "  node_counter = torch.zeros((sampler.g.num_nodes(),)).to(device)\n",
        "  edge_counter = torch.zeros((sampler.g.num_edges(),)).to(device)\n",
        "\n",
        "  N = 0\n",
        "  sampled_nodes = 0\n",
        "  for num_nodes, subgraphs_nids, subgraphs_eids in loader:\n",
        "    sampled_nodes += num_nodes\n",
        "    sampled_nodes_idx, _node_counts = torch.unique(\n",
        "        torch.cat(subgraphs_nids), return_counts=True)\n",
        "    node_counter[sampled_nodes_idx] += _node_counts\n",
        "\n",
        "    sampled_edges_idx, _edge_counts = torch.unique(\n",
        "        torch.cat(subgraphs_eids), return_counts=True)\n",
        "    edge_counter[sampled_edges_idx] += _edge_counts\n",
        "    N += len(subgraphs_nids)\n",
        "\n",
        "    if sampled_nodes > num_samples * sampler.g.num_nodes():\n",
        "      break\n",
        "    \n",
        "  return compute_norm(sampler.g, node_counter, edge_counter, N)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwb2soStNmMX"
      },
      "source": [
        "sampler = NodeSampler(graph, 100)\n",
        "aggr, loss = precompute_norm(sampler, 100, 512, 0) # num_workers = 0 due to CUDA inference\n",
        "\n",
        "assert round(aggr[1].item(), 3) == 0.014\n",
        "assert round(loss[1].item(), 2) == 0.01"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tndi489-shL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGyjwOFwpmvn"
      },
      "source": [
        "### Put all together\n",
        "\n",
        "In this task we will train the GCN using the GraphSAINT sampling approach.\n",
        "\n",
        "Firstly, we need to define the network. It will be vanilla GCN. However, we want to apply the edge and loss normalizations. So the forward function should pass the `edge_weight` to the layer inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HAHiyL-T64O"
      },
      "source": [
        "from dgl.nn import GraphConv\n",
        "\n",
        "class GCN(nn.Module):\n",
        "  def __init__(self, in_dim, out_dim, hid_dim=8, n_layers=3, dropout_rate=0.1):\n",
        "    super(GCN, self).__init__()\n",
        "    self.layers = nn.ModuleList()\n",
        "    self.layers.append(GraphConv(in_dim, hid_dim, norm=\"right\", activation=F.relu))\n",
        "    for i in range(n_layers - 2):\n",
        "      self.layers.append(GraphConv(hid_dim, hid_dim, norm=\"right\", activation=F.relu))\n",
        "    self.layers.append(GraphConv(hid_dim, out_dim, norm=\"right\"))\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "  \n",
        "  def forward(self, graph, use_norm=True):\n",
        "    h = graph.ndata[\"feat\"]\n",
        "    for layer in self.layers[:-1]:\n",
        "      h = self.dropout(h)\n",
        "      h = layer(graph, h, edge_weight=graph.edata[\"aggr_norm\"] if use_norm else None)\n",
        "    return self.layers[-1](graph, h, edge_weight=graph.edata[\"aggr_norm\"] if use_norm else None)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVmWozJKVvLx"
      },
      "source": [
        "Now let us define all requirement for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "samyltrkW1Lu"
      },
      "source": [
        "def collate(batch):\n",
        "  return batch[0]\n",
        "\n",
        "graph = graph.add_self_loop()\n",
        "sampler = NodeSampler(graph, 512)\n",
        "sampler.g.edata[\"aggr_norm\"], sampler.g.ndata[\"loss_norm\"] = \\\n",
        "  precompute_norm(sampler, 1000, 512, 0)\n",
        "sampler.g = sampler.g.to(device)\n",
        "loader = DataLoader(sampler, batch_size=1, collate_fn=collate)\n",
        "model = GCN(graph.ndata['feat'].size(1), label.max().item() + 1)\n",
        "model = model.to(device)\n",
        "evaluator = Evaluator(d_name)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_qRFam7nuE5"
      },
      "source": [
        "The one epoch trainer is usual. However, we need to apply the loss normalization technique:\n",
        "\n",
        "1. Calculate loss for each point (`reduction=\"none\"`)\n",
        "2. Multiply loss by normalization\n",
        "3. Reduce loss with mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYI6ft3TWxAz"
      },
      "source": [
        "def train(model, loader, optimizer):  \n",
        "  model.train()\n",
        "  for subgraph in tqdm(loader):\n",
        "    subgraph = subgraph.to(device)\n",
        "    subgraph = dgl.add_self_loop(subgraph)\n",
        "    p = model(subgraph)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss = F.cross_entropy(\n",
        "        p.to(torch.float32)[subgraph.ndata['is_train']], \n",
        "        subgraph.ndata['label'][subgraph.ndata['is_train']], \n",
        "        reduction=\"none\") # n x 1\n",
        "    loss = (loss * subgraph.ndata[\"loss_norm\"][subgraph.ndata['is_train']]).mean()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "\n",
        "\n",
        "def evaluate(model, g, labels, mask):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(g, use_norm=False)\n",
        "    logits = logits[mask].argmax(dim=1, keepdims=True)\n",
        "    labels = labels[mask]\n",
        "    return evaluator.eval({\n",
        "        'y_true': labels,\n",
        "        'y_pred': logits\n",
        "    })"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuAJ9vmloj0D"
      },
      "source": [
        "Now let us run the pipeline and see our results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQZZXDxduueu"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import os\n",
        "log_dir = \"./\"\n",
        "\n",
        "def run(model, loader):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "  scheduler = ReduceLROnPlateau(optimizer, factor=0.9)\n",
        "  best_acc = -1\n",
        "\n",
        "  scores = {\n",
        "        \"train\": [],\n",
        "        \"validation\": [],\n",
        "        \"test\": [],\n",
        "    }\n",
        "  for epoch in range(500):\n",
        "    train(model, loader, optimizer)\n",
        "\n",
        "    model.eval()\n",
        "    if epoch % 10 == 0:\n",
        "      clear_output()\n",
        "      scores['train'].append(evaluate(model, graph, label, train_idx)[\"acc\"])\n",
        "      scores['validation'].append(evaluate(model, graph, label, valid_idx)[\"acc\"])\n",
        "      scores['test'].append(evaluate(model, graph, label, test_idx)[\"acc\"])\n",
        "\n",
        "      plt.title(\"Score dynamics. train: {:.4f}, validation: {:.4f}, test: {:.4f}\".format(\n",
        "          scores['train'][-1], scores['validation'][-1], scores['test'][-1]))\n",
        "      plt.plot(scores['train'], label=\"train\")\n",
        "      plt.plot(scores['validation'], label=\"validation\")\n",
        "      plt.plot(scores['test'], label=\"test\")\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "      \n",
        "      if scores['validation'][-1] > best_acc:\n",
        "        best_acc = scores['validation'][-1]\n",
        "        print('new best val score:', best_acc)\n",
        "        torch.save(model.state_dict(), os.path.join(\n",
        "            log_dir, 'best_model.pkl'))\n",
        "      scheduler.step(scores['validation'][-1])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B090-q55_TLK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "21936a0a-9832-4ec0-e7c0-e73d128af727"
      },
      "source": [
        "run(model, loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 331/331 [00:03<00:00, 100.26it/s]\n",
            "100%|██████████| 331/331 [00:03<00:00, 99.68it/s]\n",
            " 37%|███▋      | 123/331 [00:01<00:02, 98.12it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYDhfvbFAtgb"
      },
      "source": [
        "$$A$$\n",
        "$$\\tilde A = A + I_n$$\n",
        "$$\\hat A = D^{-1/2} \\tilde A D^{-1/2}$$\n",
        "$$\\hat A = \\tilde A D^{-1/2}$$\n",
        "$$\\sigma(\\hat A H W)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUuqbB3PAs68"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s5dePtjhxiN8"
      },
      "source": [
        "sampler = EdgeSampler(g=graph, num_edges=256)\n",
        "sampler.g.edata[\"aggr_norm\"], sampler.g.ndata[\"loss_norm\"] = precompute_norm(sampler, 1000, 512, 0)\n",
        "sampler.g.edata[\"aggr_norm\"] = sampler.g.edata[\"aggr_norm\"].to(device)\n",
        "sampler.g.ndata[\"loss_norm\"] = sampler.g.ndata[\"loss_norm\"].to(device)\n",
        "sampler.g = sampler.g.to(device)\n",
        "loader = DataLoader(sampler, batch_size=1, collate_fn=collate)\n",
        "model = GCN(graph.ndata['feat'].size(1), label.max().item() + 1)\n",
        "model = model.to(device)\n",
        "\n",
        "run(model, loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ByIXuQf8JUL"
      },
      "source": [
        "sampler = RandomWalkSampler(num_roots=10000, length=100, g=graph)\n",
        "sampler.g.edata[\"aggr_norm\"], sampler.g.ndata[\"loss_norm\"] = precompute_norm(sampler, 1000, 512, 0)\n",
        "sampler.g = sampler.g.to(device)\n",
        "loader = DataLoader(sampler, batch_size=1, collate_fn=collate, num_workers=8)\n",
        "model = GCN(graph.ndata['feat'].size(1), label.max().item() + 1)\n",
        "model = model.to(device)\n",
        "\n",
        "run(model, loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTWAyMSeAmgx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}